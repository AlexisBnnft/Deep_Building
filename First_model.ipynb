{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from model import *\n",
    "from viz import *\n",
    "from dataset import *\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_tload('data/buildings/datasets/2024/GATES_zone-tloads.csv')\n",
    "weather = load_weather('data/buildings/datasets/2024/weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_viz(df)\n",
    "nan_viz(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tload_viz(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have time series for a given building, corresponding do each zone terminal load, a measure of how needy a zone i in term of cooling or reheat. \n",
    "\n",
    "We'll denote this:\n",
    "\n",
    "$$T_{load}^{(z,t)}$$\n",
    "\n",
    "With $t$ indexing the time and $z$ denoting the zone of the building. We have  382  zone in this building, which makes a vector of \n",
    "$$T_{load, building}^{t} \\in \\mathbb R ^{(382,1)}$$\n",
    "\n",
    "We also have a input feature timeseries, which is common for all the building as well. This includes features such as Outside Air temperautre or solar irradiation. \n",
    "\n",
    "$$W^{t}$$\n",
    "\n",
    "In the code the weather dataframe is formatted like so:\n",
    "| Date                | temperature | RH  | Tdew | wind | sun_rad | daily_rain |\n",
    "|---------------------|-------------|-----|------|------|---------|------------|\n",
    "| 2023-05-01 00:00:00 | 52.6        | 75.0| 44.8 | 9.2  | 0.0     | 0.00       |\n",
    "| 2023-05-01 01:00:00 | 52.4        | 75.0| 44.7 | 7.4  | 0.0     | 0.00       |\n",
    "| 2023-05-01 02:00:00 | 52.2        | 75.0| 44.4 | 9.0  | 0.0     | 0.00       |\n",
    "\n",
    "And the \n",
    "\n",
    "| Date                | VAV2-33 | VAV2-17   | VAV3-18 | VAV4-22    | VAV2-20 | VAV1-18 | VAV2-03   | VAV3-06 | VAV2-31 | VAV2-29 | ... | VAV2-11 | VAV2-32 | VAV4-25    | VAV4-08 | VAV1-02   | VAV0-00-4  | VAV0-04 | VAV1-12 | VAV2-18 | VAV3-15 |\n",
    "|---------------------|---------|-----------|---------|------------|---------|---------|-----------|---------|---------|---------|-----|---------|---------|------------|---------|-----------|------------|---------|---------|---------|---------|\n",
    "| 2023-05-01 00:00:00 | 0.0     | 0.000000  | 0.0     | -10.687083 | 0.0     | 0.0     | -5.494500 | 0.000000| 0.0     | -100.0  | ... | 0.0     | 0.0     | -16.662916 | 0.0     | -0.435333 | -8.518917  | 0.0     | 0.0     | 0.0     | 0.000000|\n",
    "| 2023-05-01 01:00:00 | 0.0     | -0.355917 | 0.0     | -10.881667 | 0.0     | 0.0     | -7.798417 | 0.000000| 0.0     | -100.0  | ... | 0.0     | 0.0     | -16.492833 | 0.0     | -7.894917 | -7.576250  | 0.0     | 0.0     | 0.0     | 0.000000|\n",
    "| 2023-05-01 02:00:00 | 0.0     | -0.559250 | 0.0     | -10.827083 | 0.0     | 0.0     | -6.123417 | 0.000000| 0.0     | -100.0  | ... | 0.0     | 0.0     | -16.670916 | 0.0     | -6.497750 | -8.176333  | 0.0     | 0.0     | 0.0     | -1.364750|\n",
    "\n",
    "I want to train a LSTM architecture that will for an input of the past 2 weeks of data of terminal load vector, will try to predict the next week. I also have the exact weather for the two past weeks and the predicting wek (that could be a forcecast in real life use), to help the prediction of model, as those should be correlated in some ways. \n",
    "\n",
    "Give me a way to start formatting my code to have such a model, train it and test it. I want to have september has my validation set. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "for col in df.columns[:10]:\n",
    "    plt.plot(df.loc[df.index.month == 5,col], label=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 400 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure both dataframes have datetime indices\n",
    "df.index = pd.to_datetime(df.index)\n",
    "weather.index = pd.to_datetime(weather.index)\n",
    "\n",
    "# Train the model\n",
    "model, train_losses, val_losses, train_dataset, val_dataset, train_loader, val_loader = get_trained_model(df, weather, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "# Example usage\n",
    "model_path = 'model/model.pth'\n",
    "data_path = 'model/data.pkl'\n",
    "save_all(model, train_losses, val_losses, train_dataset, val_dataset, train_loader, val_loader, model_path, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_class = TerminalLoadPredictor  # Replace with your model class\n",
    "model_path = 'model/model.pth'\n",
    "data_path = 'model/data.pkl'\n",
    "model, train_losses, val_losses, train_dataset, val_dataset, train_loader, val_loader = load_all(model_class, model_path, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct way to call visualize_results\n",
    "visualize_results(\n",
    "    model=model,\n",
    "    dataset=val_dataset,  # The dataset object\n",
    "    load_scaler=train_dataset.load_scaler,  # The actual scaler object\n",
    "    train_losses=train_losses,\n",
    "    val_losses=val_losses,\n",
    "    zones_names=df.columns,\n",
    "    sample_idx=0,\n",
    "    n_samples=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout, train_losses_dropout, val_losses_dropout, train_dataset_dropout, val_dataset_dropout, train_loader_dropout, val_loader_dropout = get_trained_model(df, weather, n_epochs=n_epochs, p_dropout=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "model_path = 'model/model_dropout.pth'\n",
    "data_path = 'model/data.pkl'\n",
    "save_all(model_dropout, train_losses_dropout, val_losses_dropout, train_dataset_dropout, val_dataset_dropout, train_loader_dropout, val_loader_dropout, model_path, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model/model_dropout.pth'\n",
    "data_path = 'model/data.pkl'\n",
    "model_dropout, train_losses_dropout, val_losses_dropout, train_dataset_dropout, val_dataset_dropout, train_loader_dropout, val_loader_dropout = load_all(model_path, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct way to call visualize_results\n",
    "visualize_results(\n",
    "    model=model_dropout,\n",
    "    dataset=val_dataset_dropout,  # The dataset object\n",
    "    load_scaler=val_dataset_dropout.load_scaler,  # The actual scaler object\n",
    "    train_losses=train_losses_dropout,\n",
    "    val_losses=val_losses_dropout,\n",
    "    zones_names=df.columns,\n",
    "    sample_idx=0,\n",
    "    n_samples=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model, model_dropout]\n",
    "train_losses_all = [train_losses, train_losses_dropout]\n",
    "val_losses_all = [val_losses, val_losses_dropout]\n",
    "model_names = ['No Dropout', 'Dropout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_results(\n",
    "    models=models,\n",
    "    train_losses=train_losses_all,\n",
    "    val_losses=val_losses_all,\n",
    "    model_names=model_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_errors, all_predictions, all_targets = calculate_errors(model_dropout, val_dataset_dropout, val_dataset_dropout.load_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from viz import plot_dataset_error, plot_bad_samples_predictions\n",
    "\n",
    "plot_dataset_error(all_errors)\n",
    "\n",
    "plot_bad_samples_predictions(all_errors, all_predictions, all_targets, N_samples=3, N_zones=10)\n",
    "plot_bad_samples_predictions(all_errors, all_predictions, all_targets, good_zones=True,N_samples=3, N_zones=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building wide prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_errors, all_predictions, all_targets = calculate_errors(model_dropout, val_dataset_dropout, val_dataset_dropout.load_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_predictions = np.concatenate([all_predictions[sample] for sample in range(all_predictions.shape[0])], axis=0)\n",
    "concatenated_predictions.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(concatenated_predictions, columns=df.columns)\n",
    "predictions_df = predictions_df.map(lambda x: max(-100,x))\n",
    "predictions_df.index = df.iloc[-concatenated_predictions.shape[0]:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import error_viz\n",
    "error_df = predictions_df - df.iloc[-concatenated_predictions.shape[0]:]\n",
    "# Sort the columns in ascending order of error\n",
    "error_df = error_df[error_df.abs().mean().sort_values().index]\n",
    "error_viz(error_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
